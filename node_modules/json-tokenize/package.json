{
  "_from": "json-tokenize",
  "_id": "json-tokenize@0.3.0",
  "_inBundle": false,
  "_integrity": "sha1-aMnW+aeqWCVCXYINE7PBjoUFm5g=",
  "_location": "/json-tokenize",
  "_phantomChildren": {},
  "_requested": {
    "type": "tag",
    "registry": true,
    "raw": "json-tokenize",
    "name": "json-tokenize",
    "escapedName": "json-tokenize",
    "rawSpec": "",
    "saveSpec": null,
    "fetchSpec": "latest"
  },
  "_requiredBy": [
    "#USER",
    "/"
  ],
  "_resolved": "https://registry.npmjs.org/json-tokenize/-/json-tokenize-0.3.0.tgz",
  "_shasum": "68c9d6f9a7aa5825425d820d13b3c18e85059b98",
  "_spec": "json-tokenize",
  "_where": "C:\\Users\\Dominik\\Desktop\\Cards Against Me",
  "author": {
    "name": "queckezz",
    "email": "fabian.eichenberger@gmail.com"
  },
  "bugs": {
    "url": "https://github.com/queckezz/elementx/issues"
  },
  "bundleDependencies": false,
  "deprecated": false,
  "description": "Splits a JSON string into an annotated list of tokens",
  "devDependencies": {
    "ava": "^0.18.1",
    "buble": "^0.15.2",
    "husky": "^0.13.1",
    "standard": "^7.0.1"
  },
  "homepage": "https://github.com/queckezz/elementx#readme",
  "keywords": [
    "json",
    "tokenize",
    "parse",
    "tokens",
    "lexer",
    "lexical analysis"
  ],
  "license": "MIT",
  "main": "dist.js",
  "name": "json-tokenize",
  "repository": {
    "type": "git",
    "url": "git+https://github.com/queckezz/elementx.git"
  },
  "scripts": {
    "precommit": "npm test",
    "prepublish": "buble index.js > dist.js",
    "test": "standard && ava"
  },
  "version": "0.3.0"
}
